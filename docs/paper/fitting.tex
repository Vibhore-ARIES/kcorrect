\documentclass[10pt,preprint]{aastex}

\newcommand{\vv}[1]{{\bf #1}}
\newcommand{\df}{\delta}
\newcommand{\dfft}{{\tilde{\delta}}}
\newcommand{\betaft}{{\tilde{\beta}}}
\newcommand{\erf}{{\mathrm{erf}}}
\newcommand{\erfc}{{\mathrm{erfc}}}
\newcommand{\Step}{{\mathrm{Step}}}
\newcommand{\ee}[1]{\times 10^{#1}}
\newcommand{\avg}[1]{{\langle{#1}\rangle}}
\newcommand{\Avg}[1]{{\left\langle{#1}\right\rangle}}
\def\simless{\mathbin{\lower 3pt\hbox
	{$\,\rlap{\raise 5pt\hbox{$\char'074$}}\mathchar"7218\,$}}} % < or of order
\def\simgreat{\mathbin{\lower 3pt\hbox
	{$\,\rlap{\raise 5pt\hbox{$\char'076$}}\mathchar"7218\,$}}} % > or of order
\newcommand{\iras}{{\sl IRAS\/}}
\newcommand{\petroratio}{{{\mathcal{R}}_P}}
\newcommand{\petroradius}{{{r}_P}}
\newcommand{\petronumber}{{{N}_P}}
\newcommand{\petroratiolim}{{{\mathcal{R}}_{P,\mathrm{lim}}}}
\newcommand{\band}[2]{\ensuremath{^{{#1}}\!{#2}}}

\newcommand{\kversion}{{\tt v1\_11}}

\setlength{\footnotesep}{9.6pt}

\newcounter{thefigs}
\newcommand{\fignum}{\arabic{thefigs}}

\newcounter{thetabs}
\newcommand{\tabnum}{\arabic{thetabs}}

\newcounter{address}

\slugcomment{To be submitted to \aj}

\shortauthors{Blanton {\it et al.} (2005)}
\shorttitle{Template star-formation histories}

\begin{document}

\title{ Creating spectroscopic templates using heterogeneous data}

\author{
Michael R. Blanton\altaffilmark{\ref{NYU}} and 
Sam Roweis\altaffilmark{\ref{NYU}}}

\setcounter{address}{1}
\altaffiltext{\theaddress}{
\stepcounter{address}
New York University, Department of Physics, 4 Washington Place, New
York, NY 10003
\label{NYU}}
\clearpage

\begin{abstract}
Astronomers have a huge set of well-calibrated photometric and
spectroscopic data on galaxies from recent large surveys at all
redshifts, such as (at low redshift) the GALaxy Evolution eXplorer in
the ultraviolet, the Sloan Digital Sky Survey in the optical, and the
Two-Micron All Sky Survey in the near infrared, and (at higher
redshifts) the Deep Extragalactic Evolutionary Probe 2 and the Great
Observatories Origins Deep Survey.  However, this data comes in a
rather heterogeneous form --- sometimes in the form of
spectrophotometry, sometimes in the form of broad-band photometry. In
addition, broad-band photometry suffers from two forms of
heterogeneity: system responses differ among different surveys, and
galaxies are observed at many different redshifts (and the system
responses therefore differ among all galaxies in the rest frame).  How
can we explore this very heterogeneous set of data?  Here we present
an implementation of an algorithm for fitting star-formation histories
to these data. Our approach is to restrict the problem by trying to
explain the observations of each galaxy as a nonnegative linear
combination of a small set of star-formation history templates.  The
algorithm has almost arbitrary freedom in choosing the set of
templates, but it must explain every galaxy in terms of a nonnegative
sum of the same small set.  Our algorithm can handle whatever spectral
or broad-band information one has on each galaxy.  The results of the
algorithm have scientific applications --- such as exploring the
star-formation histories of galaxies, how they vary with environment,
how they correlate with other properties, and how they change with
redshift. In addition, they have technical applications --- such as
$K$-corrections, photometric redshifts, and continuum-fitting of
spectra. This algorithm and its ilk are likely to become more and more
useful as astronomers continue to combine large sets of inhomogeneous
data.
\end{abstract}

\keywords{galaxies: fundamental parameters --- galaxies: photometry
--- galaxies: statistics}

\section{Motivation}
\label{motivation}

Astronomers have observed the broad-band colors and spectra of a huge
number of galaxies in the Universe, in many different passbands.  For
example, at low redshift the Galaxy Evolution Explorer (GALEX; {\bf
ref}) observes in the ultraviolet (UV), the Sloan Digital Sky Survey
(SDSS; \citealt{york00a}) observes spectroscopically and
photometrically in the optical, and the Two-Micron All Sky Survey
(2MASS; \citealt{strutskie97a}) observes in the near infrared
(NIR). At higher redshifts, the Deep Extragalactic Evolutionary Probe
2 (DEEP2; {\bf ref} and the Great Observatories Origins Deep Survey
(GOODS; {\bf ref}) observe in the rest-frame UV. These and other data
sets provide a huge set of information about galaxy colors and spectra
which we can use to help understand their star-formation histories.

However, this data comes in rather heterogeneous forms. Some of the
information is spectrophotometric, and some of it is broad-band
photometry. Broad-band photometry differs among different instruments:
for example, the SDSS uses the $ugriz$ bands to observe in the
optical, whereas DEEP2 uses the $BRI$ bands. In addition, these bands
probe different parts of the rest-frame galaxy spectrum at different
redshifts. So the constraints these observations apply to our fits of
the star-formation histories of these objects vary considerably from
one object to another.

On the other hand, from the spectroscopic observations we know the
galaxy spectra reside in a low-dimensional locus. Principal Component
Analysis (PCA) of galaxy spectra, introduced by \citet{connolly94a}
and applied many times since then ({\bf more refs}; \citealt{yip05a}),
demonstrates that most of the variance in the distribution of galaxies
in spectral space can be explained using a few templates. This means
that, in the linear space of all possible spectra, galaxies exist in
only a small locus. Therefore, even with very heterogeneous data, we
should be able to determine the properties of this locus.

Here we present an approach to combining the heterogeneous data
described above in order to determine the properties of the locus of
galaxy spectra. Rather than taking the model-free approach used by
PCA, we here restrict the space of possible spectra to those predicted
from the high resolution stellar population synthesis model of
\citet{bruzual03a} and the emission line models of {\bf mappings
ref}.  This approach both constrains the problem appropriately and
yields a natural theoretical interpretation of the results in terms of
star-formation histories.

In a nutshell, our algorithm does the following. Given the
observations (and uncertainties of those observations) available for
each galaxy, it finds the nonnegative linear combination of $N$
template star-formation histories which best predict those
observations in the $\chi^2$ sense. Given the entire set of galaxy
observations available, it also fits for those template star-formation
histories. The technical name for this algorithm is Nonnegative Matrix
Factorization (NMF).

This approach is similar to PCA in that it finds the small spectral
subspace in which galaxies exist, and can in some ways be thought of
as ``nonnegative PCA.''  However, our method has several advantages
over the standard PCA approach. First, it has a natural physical
interpretation associated with that spectral subspace, which is the
corresponding subspace of all possible star-formation
histories. Second, it naturally handles data uncertainties and missing
data, which allows it to ignore that variation which is due purely to
statistical errors.  Third, it handles the complications of observing
galaxy spectra photometrically using broad-band filters.

The results of this work yield, first of all, a set of templates which
are useful for any number of technical tasks, for example
$K$-corrections, evolution corrections, photometric redshifts, and
continuum subtraction of galaxy spectra. Second, the fits to
individual galaxies provide a theoretical interpretation of their
emission, in terms of their stellar masses, dust content, and
star-formation histories.

In Section \ref{algorithm} we present and test the NMF algorithm
itself. All of the software we use is available publicly in the {\tt
idlutils}, {\tt idlspec2d} and {\tt kcorrect} packages.  In Section
\ref{data} we present the data we use, most of which is publicly
available. In Section \ref{results}, we present the templates we have
found for our data set. We summarize in Section
\ref{summary}. Separate papers describe the application of these
results to the scientific and technical questions described above.

\section{Method}
\label{algorithm}

Our method is fundamentally very simple. We take $N$ star-formation
history templates and all of our observations of our galaxies.  We
then find the templates and (for each galaxy) their linear combination
by minimizing the $\chi^2$ difference between the actual observations
and the model predictions for those observations. In practice there
are some complications and details to consider. In Section \ref{model}
we describe how we express the star-formation histories of each
galaxy.  In Section \ref{spectra} we explain the models we use to
convert these star-formation histories into spectra. In Section
\ref{observe} we describe how a particular star-formation history can
be transformed into all possible observations for that galaxy. In
Section \ref{nmf} we describe our minimization procedure.

\subsection{Model for the star-formation histories}
\label{model}

Our model for the star-formation history of each galaxy $i$ is a linear
combination of $N$ templates, as follows:
\begin{equation}
\label{stellar}
G_i(t, m, d) = \sum_{i=0}^{N-1} a_{ik} T_k(t, m, \tau_V).
\end{equation}
$G_i(t, m, \tau_V)$ is the star-formation history of each galaxy $i$,
described as the stellar mass (in solar masses) formed $t$ years ago,
with metallicity $m$, and currently obscured by $\tau_V$ magnitudes in
the $V$ band. $T_k(t, m, \tau_V)$ is the star-formation history of one
of $N$ templates out of which we allow ourselves to build each
galaxy. We restrict to nonnegative combinations of these templates
($a_{ik} \ge 0$).

Each template is in turn expressed as a linear combination of a set of
instantaneous bursts:
\begin{equation}
T_k(t, m, d) = 
\sum_{l=0}^{N_t-1} 
\sum_{n=0}^{N_m-1} 
\sum_{p=0}^{N_\tau-1} 
t_{k,lmn} 
\delta^D(t-t_l)
\delta^D(m-m_n)
\delta^D(\tau_V-\tau_{V,p})
\end{equation}
That is, for each template $k$ a certain mass in stars $t_{k,lmn}$
(expressed in solar masses) were formed time $t_l$ ago with
metallicity $m_n$, and are at the time of observation obscured by
$\tau_V$ magnitudes of dust in the $V$ band.

As described in Section \ref{spectra}, these star-formation histories
can be converted into spectra using population synthesis models.

\subsection{Model for the ionized gas}

In the optical, the other important contribution to the flux other
than the stellar light is emission from ionized gas. Depending on how
it is ionized and what its metallicity is, the recombination of this
gas can yield rather different spectra. 

Thus, we treat the gas as a sum of the same templates:
\begin{equation}
\label{emission}
E_i(m, q) = \sum_{i=0}^{N-1} a_{ik} S_k(m, q). 
\end{equation}
$E_i(m, q)$ is the amount of gas in each galaxy with metallicity $m$
and ionization parameter $q$.  $S_k(m, q)$ is the amount of such gas
in each of our $N$ templates.  We constrain the $a_{ik}$ in this
equation to be the same as that in Equation \ref{stellar} for the
star-formation histories. That is, each star formation history
templates $T_k{t, m, \tau_V}$ will be associated with the
corresponding distribution of ionized gas $S_k(m,q)$. 

Again, each template is actually a sum of delta functions:
\begin{equation}
S_k(m, q) = 
\sum_{r=0}^{N_m-1} 
\sum_{s=0}^{N_q-1} 
t_{k,rs}'
\delta^D(m-m_r)
\delta^D(q-q_s)
\end{equation}
where for each metallicity $m_r$ and ionization parameter $q_s$ we 
have a prediction for the emergent line fluxes, which we describe in
Section \ref{spectra}. 




\subsection{Predicted spectra from the star-formation histories and
ionized gas}
\label{spectra}


Note that we do not {\it have} to limit our spectral library to those
predicted by star-formation histories or the emission line models. In
fact, we can add arbitrary spectra in this step to account for
emission lines, polycyclic aromatic hydrocarbon (PAH) emission in the
mid-infrared, active galactic nuclei in the ultraviolet, or any other
constituent of galaxies.

\subsection{Observations of the predicted spectra}
\label{observe}

\subsection{Summary of the problem we want to solve}
\label{problem}

\section{Non-negative matrix factorization to find the best templates}
\label{nmf}

\section{Data}
\label{data}

\section{Results}
\label{results}

\section{Summary}
\label{summary}


\acknowledgments

Funding for the creation and distribution of the SDSS Archive has been
provided by the Alfred P. Sloan Foundation, the Participating
Institutions, the National Aeronautics and Space Administration, the
National Science Foundation, the U.S. Department of Energy, the
Japanese Monbukagakusho, and the Max Planck Society. The SDSS Web site
is {\tt http://www.sdss.org/}.

The SDSS is managed by the Astrophysical Research Consortium (ARC) for
the Participating Institutions. The Participating Institutions are The
University of Chicago, Fermilab, the Institute for Advanced Study, the
Japan Participation Group, The Johns Hopkins University, Los Alamos
National Laboratory, the Max-Planck-Institute for Astronomy (MPIA),
the Max-Planck-Institute for Astrophysics (MPA), New Mexico State
University, Princeton University, the United States Naval Observatory,
and the University of Washington.
 
\begin{thebibliography}{DUM}
\input{bib_paper.tex}
\end{thebibliography}

\newpage

%\include{fitting_tables}

\include{fitting_figures}

\end{document}
